{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHcSf7rgHUHz60Af9jPfTx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajwinder03334/ASSIGNMENT3/blob/master/assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Exercise 1\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Step 0: Read data into a pandas dataframe\n",
        "data = pd.read_csv('data_banknote_authentication.csv')\n",
        "\n",
        "# Step 1: Split data into features (X) and target variable (y)\n",
        "X = data.drop('class', axis=1)\n",
        "y = data['class']\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "# Step 3: Use support vector classifier with linear kernel\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on the testing data and compute confusion matrix and classification report\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "conf_matrix_linear = confusion_matrix(y_test, y_pred_linear)\n",
        "class_report_linear = classification_report(y_test, y_pred_linear)\n",
        "\n",
        "# Step 5: Repeat steps 3 and 4 for the radial basis function kernel\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "conf_matrix_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "class_report_rbf = classification_report(y_test, y_pred_rbf)\n",
        "\n",
        "# Step 6: Compare the two SVM models\n",
        "# Compare the two SVM models\n",
        "print(\"Performance metrics for Linear Kernel SVM:\")\n",
        "print(conf_matrix_linear)\n",
        "print(class_report_linear)\n",
        "\n",
        "print(\"\\nPerformance metrics for RBF Kernel SVM:\")\n",
        "print(conf_matrix_rbf)\n",
        "print(class_report_rbf)\n",
        "\n",
        "Exercise 2\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Step 0: Read data into a pandas dataframe\n",
        "data = pd.read_csv('weight-height.csv')\n",
        "\n",
        "# Step 1: Pick the target variable y as weight in kilograms, and the feature variable X as height in centimeters\n",
        "X = data['Height'].values.reshape(-1, 1)  # Reshape to 2D array for sklearn\n",
        "y = data['Weight']\n",
        "\n",
        "# Step 2: Split the data into training and testing sets with 80/20 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Scale the training and testing data using normalization and standardization\n",
        "scaler_norm = MinMaxScaler()\n",
        "X_train_norm = scaler_norm.fit_transform(X_train)\n",
        "X_test_norm = scaler_norm.transform(X_test)\n",
        "\n",
        "scaler_std = StandardScaler()\n",
        "X_train_std = scaler_std.fit_transform(X_train)\n",
        "X_test_std = scaler_std.transform(X_test)\n",
        "\n",
        "# Step 4: Fit a KNN regression model with k=5 to the training data without scaling\n",
        "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
        "knn_reg.fit(X_train, y_train)\n",
        "y_pred = knn_reg.predict(X_test)\n",
        "r2_unscaled = r2_score(y_test, y_pred)\n",
        "\n",
        "# Step 5: Repeat step 4 for normalized data\n",
        "knn_reg.fit(X_train_norm, y_train)\n",
        "y_pred_norm = knn_reg.predict(X_test_norm)\n",
        "r2_normalized = r2_score(y_test, y_pred_norm)\n",
        "\n",
        "# Step 6: Repeat step 4 for standardized data\n",
        "knn_reg.fit(X_train_std, y_train)\n",
        "y_pred_std = knn_reg.predict(X_test_std)\n",
        "r2_standardized = r2_score(y_test, y_pred_std)\n",
        "\n",
        "# Step 7: Compare the models in terms of their R2 value\n",
        "print(\"R2 value for unscaled data:\", r2_unscaled)\n",
        "print(\"R2 value for normalized data:\", r2_normalized)\n",
        "print(\"R2 value for standardized data:\", r2_standardized)"
      ],
      "metadata": {
        "id": "1N0sZOcAUSRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}